{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03b0b36-5598-4a9e-aa20-a5abcdabef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import json\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from stability_sdk import client\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "    \n",
    "import os\n",
    "with open('../cohere_api_key.txt', 'r') as f:\n",
    "    cohere_api_key = f.read()\n",
    "with open('../stability_api_key.txt', 'r') as f:\n",
    "    stability_api_key = f.read()\n",
    "    \n",
    "os.environ[\"COHERE_KEY\"] = cohere_api_key\n",
    "os.environ[\"STABILITY_KEY\"] = stability_api_key\n",
    "del cohere_api_key\n",
    "del stability_api_key\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from app.story_generator.segmentation import StoryDivider\n",
    "from app.story_generator.generation import StoryGenerator, PromptGenerator, add_newline_at_the_end\n",
    "# from tests.image_generation_test import get_segmented_story, summarize_story\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a319384-3dcd-43f8-a976-63ca806bbcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cohere\n",
    "# with open('../cohere_api_key.txt', 'r') as f:\n",
    "#     cohere_api_key = f.read()\n",
    "# co = cohere.Client(cohere_api_key)\n",
    "\n",
    "# n_try = 1\n",
    "# while True:\n",
    "#     print(n_try)\n",
    "#     n_try += 1\n",
    "#     response = co.generate(\n",
    "#       prompt='xd',\n",
    "#         num_generations=5,\n",
    "#         max_tokens=300\n",
    "#     )\n",
    "    \n",
    "#     for r in response.generations:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6aa1ccb-c531-403e-bfa7-11eb9dcdc9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cohere\n",
    "# with open('../cohere_api_key.txt', 'r') as f:\n",
    "#     cohere_api_key = f.read()\n",
    "# co = cohere.Client(cohere_api_key)\n",
    "\n",
    "\n",
    "# response = co.tokenize(\n",
    "#   text=''' '''\n",
    "# )\n",
    "\n",
    "\n",
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7330df71-d62f-42ae-87cb-65d72acee407",
   "metadata": {},
   "source": [
    "<h1>Generation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7380fb3-2fc4-4556-a5c5-1cd87e7f7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_stories(n=3):\n",
    "    stories_path = os.path.join(os.path.abspath(''), os.pardir,\n",
    "                                \"data\", \"stories\", \"fairy_tales.json\")\n",
    "    with open(stories_path, \"rb\") as f:\n",
    "        stories = json.load(f)\n",
    "        assert n <= len(stories), f'Tried to get {n} stories while is only {len(stories)} stories in the database'\n",
    "        example_stories = list(np.random.choice(stories, size=n, replace=False))\n",
    "        \n",
    "    return example_stories\n",
    "\n",
    "def get_segment_of_stories(stories: list, segment_idx: int, handle_too_big_index=True,\n",
    "                           n_pages=None, sentences_per_page=3):\n",
    "    segmented_stories = []\n",
    "    for s in stories:\n",
    "        seg = StoryDivider(s[\"title\"], s[\"text\"])\n",
    "        segmented = seg.divide_story_into_segments(n_pages=n_pages, sentences_per_page=sentences_per_page)\n",
    "        if handle_too_big_index and segment_idx >= len(segmented):\n",
    "            index = len(segmented) - 1\n",
    "            \n",
    "        result = s.copy()\n",
    "\n",
    "        text = segmented[segment_idx]\n",
    "        result.update({'text': text})\n",
    "        segmented_stories.append(result)\n",
    "        \n",
    "    return segmented_stories\n",
    "\n",
    "def get_segments_and_continuations(stories: list, n_pages=None, sentences_per_page=3):\n",
    "    segmented_stories = []\n",
    "    for s in stories:\n",
    "        seg = StoryDivider(s[\"title\"], s[\"text\"])\n",
    "        segmented = seg.divide_story_into_segments(n_pages=n_pages, sentences_per_page=sentences_per_page)\n",
    "        \n",
    "        segment_idx = np.random.randint(0, len(segmented)-2)\n",
    "            \n",
    "        result = s.copy()\n",
    "        prev_text = segmented[segment_idx]\n",
    "        cont_text = segmented[segment_idx+1]\n",
    "        result.update({'Previous Part': prev_text, 'Continuation': cont_text})\n",
    "        del result['text']\n",
    "        segmented_stories.append(result)\n",
    "        \n",
    "    return segmented_stories\n",
    "\n",
    "def hard_filter_results(results, stop_seq, disallowed_strings):\n",
    "    # results = results.loc[results['generation'].str.contains(stop_seq)]\n",
    "    \n",
    "    mask = None\n",
    "    for s in disallowed_strings:\n",
    "        new_mask = ~results['generation'].str.contains(s, regex=False)\n",
    "        if mask is None:\n",
    "            mask = new_mask\n",
    "        else:\n",
    "            mask = mask & new_mask\n",
    "    results = results.loc[mask]\n",
    "    return results\n",
    "\n",
    "def postprocess_results(results, stop_seq):\n",
    "    results['generation'] = results['generation'].str.replace(stop_seq, '', regex=False)\n",
    "    results['generation'] = results['generation'].str.replace('\\s+$', '', regex=True) # delete white characters at the end of string\n",
    "    \n",
    "    mask = (results['generation'].str[-1] != '.') & (results['generation'].str[-1] != '!') \\\n",
    "        & (results['generation'].str[-1] != '?') & (results['generation'].str[-1] != '\"')\n",
    "    results.loc[mask, 'generation'] += '.' # ensure there is a dot at the end of the sentence\n",
    "    return results\n",
    "\n",
    "def print_result(result, parameters, keys_used, max_words=1500):\n",
    "    starting_string = ''\n",
    "    break_used = False\n",
    "    for param, key in zip(parameters, keys_used[:-1]):\n",
    "        starting_string += f'{key.title()}: '\n",
    "        if param:\n",
    "            starting_string += param\n",
    "        else: \n",
    "            break_used = True\n",
    "            break\n",
    "\n",
    "        starting_string = add_newline_at_the_end(starting_string)\n",
    "\n",
    "    if not break_used:\n",
    "        starting_string += f'{keys_used[-1].title()}:'\n",
    "\n",
    "    for i, row in result.iterrows():\n",
    "        print('-'*50)\n",
    "        print('likelihood:', row['likelihood'])\n",
    "\n",
    "        text = starting_string + row[\"generation\"]\n",
    "        if len(text.split(' ')) > max_words:\n",
    "            print('Text too long')\n",
    "            continue\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72914dd-c716-47f5-9026-1a8a81f3bd65",
   "metadata": {},
   "source": [
    "<h2>Step 0: Set internal parameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6df1e4e-a64b-4f86-b9ba-e5c57f1ed19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 150\n",
    "STOP_SEQUENCES = ['--']\n",
    "TEMPERATURE = 0.75\n",
    "MODEL = 'xlarge'\n",
    "MIN_P = 0.8\n",
    "FREQ_PENALTY = 0.0 #0.3\n",
    "PRESENCE_PENALTY = 1.0 #0.5\n",
    "N_EXAMPLE_STORIES = 5\n",
    "\n",
    "# I found manually some tokens that are sometimes problem in our generation\n",
    "DISALLOWED_TOKENS = {\n",
    "    'https': 1099,\n",
    "    ' https': 1595,\n",
    "    '://': 695,\n",
    "    '::': 5280,\n",
    "    ' ::': 13361,\n",
    "    '/': 48,\n",
    "    ' /': 1040,\n",
    "    'http': 2676,\n",
    "    ' http': 2930,\n",
    "    '#': 36,\n",
    "    ' #': 1462,\n",
    "    '(': 41,\n",
    "    ' (': 367,\n",
    "    ')': 42,\n",
    "    ' )': 3479,\n",
    "}\n",
    "DISALLOWED_STRINGS = set([re.sub('^\\s|\\s$', '', key) for key in DISALLOWED_TOKENS.keys()])\n",
    "\n",
    "SUMM_GEN_HEADER = f'Assignment: Write a short summary of {N_EXAMPLE_STORIES+1} stories for children based on titles given. Your stories should be in a old-school book format.'\n",
    "KEYS_TO_USE_FOR_SUMMARY = ['title', 'summary']\n",
    "\n",
    "BEG_GEN_HEADER = 'Assignment: Write a beginning of {} stories for children based on titles and summary of the story given. Your stories should be in a old-school book format.'\n",
    "KEYS_TO_USE_FOR_BEGINNING = ['title', 'summary', 'text']\n",
    "\n",
    "KEYS_TO_USE_FOR_CONTINUATION = ['title', 'summary', 'Previous Part', 'Continuation']\n",
    "CONT_GEN_HEADER = 'Assignment: Write a continuations of {} stories for children based on titles, summary and the previous part given the story given. Your stories should be in a old-school book format.'\n",
    "\n",
    "KEYS_TO_USE_FOR_ENDING = ['title', 'summary', 'Previous Part', 'Ending']\n",
    "END_GEN_HEADER = 'Assignment: Write an ending of {} stories for children based on titles, summary and the previous part given the story given. Your stories should be in a old-school book format.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89178c53-9a9a-4855-a113-b50217ec530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_result(results):\n",
    "    return results.loc[((results['generation'].str.split('.').str.len() - 5).abs()).idxmin(), 'generation']\n",
    "\n",
    "def generate_segment(example_stories, keys_to_use, header, parameters, story_generator=None, check_n_tokens=True):\n",
    "    prompt_gen = PromptGenerator(stories=example_stories, keys_to_use=keys_to_use, header=header,\n",
    "                                 parameters=parameters, stop_token=STOP_SEQUENCES[0])\n",
    "    prompt = prompt_gen.generate_prompt_for_story(check_n_tokens=check_n_tokens)\n",
    "\n",
    "    if story_generator is None:\n",
    "        story_gen = StoryGenerator(\n",
    "            prompt=None, model=MODEL, max_tokens=MAX_TOKENS, stop_sequences=STOP_SEQUENCES, temperature=TEMPERATURE,\n",
    "            min_p=MIN_P, frequency_penalty=FREQ_PENALTY, presence_penalty=PRESENCE_PENALTY, disallowed_tokens=DISALLOWED_TOKENS.values())\n",
    "\n",
    "    # Generate in a loop in order to always have at least one viable generated output\n",
    "    results = []\n",
    "    try_number = 1\n",
    "    while len(results) == 0:\n",
    "        if try_number > 1:\n",
    "            print('Try:', try_number)\n",
    "\n",
    "        # generating\n",
    "        results = story_generator.generate(prompt=prompt, num_generations=5)\n",
    "        try_number += 1 \n",
    "\n",
    "        # filtering\n",
    "        results = hard_filter_results(results, STOP_SEQUENCES[0], DISALLOWED_STRINGS)\n",
    "\n",
    "    # postprocessing resutls\n",
    "    results = postprocess_results(results, STOP_SEQUENCES[0])\n",
    "    \n",
    "    # choosing best results\n",
    "    result = choose_best_result(results)\n",
    "    \n",
    "    return result, prompt, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0431f-d5f4-4c1c-b25d-813273b28829",
   "metadata": {},
   "source": [
    "<h2>Step 1: Get params from user</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b82eff-6fb3-4ced-b3ac-5014a7763fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_stories = get_n_stories(3) # could be based on some params (try tags?)\n",
    "n_pages = 5 # pages to generate\n",
    "title = 'Knight Ulrich And A Fearsome Dragon' # title for the story (could be empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adebc5-0a28-4153-b5c7-54bfd4178a63",
   "metadata": {},
   "source": [
    "<h2>Step 2: Generate short description</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809ae99f-73aa-4d8b-a6ad-39141169f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWarning: Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if title:\n",
    "    parameters = [title]\n",
    "else:\n",
    "    parameters = []\n",
    "\n",
    "story_gen = StoryGenerator(\n",
    "    prompt=None, model=MODEL, max_tokens=MAX_TOKENS, stop_sequences=STOP_SEQUENCES, temperature=TEMPERATURE,\n",
    "    min_p=MIN_P, frequency_penalty=FREQ_PENALTY, presence_penalty=PRESENCE_PENALTY, disallowed_tokens=DISALLOWED_TOKENS.values())\n",
    "\n",
    "summary, summ_prompt, summ_results = generate_segment(example_stories, KEYS_TO_USE_FOR_SUMMARY, SUMM_GEN_HEADER, parameters, story_generator=story_gen)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef492c-2abb-43ed-bd50-7088e73eb911",
   "metadata": {},
   "source": [
    "<h3>Next Step: Serve our summary to user</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d21548-fdb0-4c1c-bdae-11ddd3a29cca",
   "metadata": {},
   "source": [
    "Here we have 4 possibilities:\n",
    "<ul>\n",
    "    <li><strong>User accepts the summary and goes to Step 3</strong></li>\n",
    "    <li>User edits the summary, then accepts it and goes to Step 3</li>\n",
    "    <li>User (re)generates the summary once more by going to Step 2</li>\n",
    "    <li>User rejects te summary and goes back to Step 1 (home page)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04df343-baba-4c6e-afa7-2658c3a794d3",
   "metadata": {},
   "source": [
    "<h2>Step 3: Generate story beginning</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1643c4-3b48-40fc-8606-ad70bb923389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWarning: Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if title:\n",
    "    parameters = [title, summary]\n",
    "else:\n",
    "    parameters = [summary]\n",
    "    \n",
    "story_beginnings = get_segment_of_stories(example_stories, 0)\n",
    "header = BEG_GEN_HEADER.format(len(story_beginnings)+1)\n",
    "\n",
    "beginning, beg_prompt, beg_results = generate_segment(story_beginnings, KEYS_TO_USE_FOR_BEGINNING, header, parameters, story_generator=story_gen)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19658f3-d8e8-4dc8-83ef-2e73dee7ff23",
   "metadata": {},
   "source": [
    "<h3>Next Step: Serve our beginning to user</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7052a-e079-4d49-a65f-5d82600c28c0",
   "metadata": {},
   "source": [
    "Here we have 4 possibilities:\n",
    "<ul>\n",
    "    <li><strong>User accepts the beginning and goes to Step 4</strong></li>\n",
    "    <li>User edits the beginning, then accepts it and goes to Step 4</li>\n",
    "    <li>User (re)generates the beginning once more by going to Step 3</li>\n",
    "    <li>User rejects te beginning and goes back to Step 1 (home page)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64cbad-4693-41fc-880b-cbb5fe8fbd41",
   "metadata": {},
   "source": [
    "<h2>Step 4: Generate story continuation</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33335a62-62ca-4aff-a0d4-e8212d86ff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an error with Cohere server, retrying after 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWarning: Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n",
      "\u001b[0m\n",
      "\u001b[93mWarning: Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n",
      "\u001b[0m\n",
      "\u001b[93mWarning: Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "continuations_to_generate = n_pages - 2\n",
    "\n",
    "if title:\n",
    "    parameters = [title, summary, beginning]\n",
    "else:\n",
    "    parameters = [summary, beginning]\n",
    "    \n",
    "continuations = []\n",
    "cont_prompts = []\n",
    "cont_results_list = []\n",
    "    \n",
    "for i in range(continuations_to_generate):\n",
    "    example_continuations = get_segments_and_continuations(example_stories)\n",
    "    while True:\n",
    "        header = CONT_GEN_HEADER.format(len(example_continuations)+1)\n",
    "        try:\n",
    "            continuation, cont_prompt, cont_results = generate_segment(example_continuations, KEYS_TO_USE_FOR_CONTINUATION, header, parameters, story_generator=story_gen)\n",
    "        except AssertionError:\n",
    "            example_continuations = example_continuations[:-1]\n",
    "            continue\n",
    "        break # break if there was no error\n",
    "        \n",
    "    continuations.append(continuation)\n",
    "    # temporary also save prompts and results for debugging\n",
    "    cont_prompts.append(cont_prompt)\n",
    "    cont_results_list.append(cont_results)\n",
    "    \n",
    "    if title:\n",
    "        parameters = [title, summary, continuation]\n",
    "    else:\n",
    "        parameters = [summary, continuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886cb352-d8e0-4e1b-99c5-4b7456e31605",
   "metadata": {},
   "source": [
    "<h2>Step 5: Generate story ending</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb86a276-63b6-4aa0-8586-fd05faa6579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWarning: Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if title:\n",
    "    parameters = [title, summary, continuation]\n",
    "else:\n",
    "    parameters = [summary, continuation]\n",
    "    \n",
    "story_endings = [\n",
    "    {'Previous Part': story_bef_end.pop('text'), 'Ending': story_end['text'], **story_bef_end} \\\n",
    "    for story_bef_end, story_end in zip(get_segment_of_stories(example_stories, -2), get_segment_of_stories(example_stories, -1))\n",
    "]\n",
    "\n",
    "header = END_GEN_HEADER.format(len(story_beginnings)+1)\n",
    "\n",
    "ending, end_prompt, end_results = generate_segment(story_endings, KEYS_TO_USE_FOR_ENDING, header, parameters, story_generator=story_gen, check_n_tokens=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b9fe223-e8ae-460b-ae82-25bf6424b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: Knight Ulrich And A Fearsome Dragon\n",
      "Summary:  A brave knight is traveling through the forest when he comes across a giant dragon, whose body takes up most of the path. At first, the dragon is very friendly, and they start chatting. But then the dragon gets angry and tries to attack the knight! The knight draws his sword and kills the dragon. Then he continues on his way. But soon, he meets another dragon!\n",
      "\n",
      "Story:\n",
      "\n",
      " A knight was traveling in the woods. It was dark and he didn't know where he was going. As he passed by a cave, he saw something move. \"Who's there?\" called the knight. He walked into the cave and saw a giant dragon curled up and snoring. The knight was frightened, but he couldn't leave the dragon behind. So he decided to hide behind a tree and wait. Just then, the dragon woke up and started roaring. The knight had never killed anyone before, but he had no choice but to kill the dragon. His sword struck the dragon's heart. The dragon screamed and fumbled about. His enormous body hit the roof of the cave and fell to the ground. As the sun sank in the west, the knight was pleased that he had escaped death. He had killed the dreadful dragon and looked forward to entering the city the next morning. Suddenly, he heard a loud roar behind him. It was the other dragon! It was bigger than the first one and its mouth was filled with large, sharp teeth.  This time the knight was not so lucky. He tried to escape, but he was too slow. The dragon caught him, swallowed him, and left nothing behind. The dragon went back to his lair, having eaten a good meal. The knight's horse galloped home alone. The castle was in an uproar, because the king and all his men thought the knight had been killed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story = f'''\n",
    "Title: {title}\n",
    "Summary: {summary}\n",
    "\n",
    "Story:\n",
    "\n",
    "{beginning + ''.join(continuations) + ending}\n",
    "'''\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b46b07d-2efa-4c5e-ab9a-da05fb9636fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A knight was traveling in the woods. It was dark and he didn\\'t know where he was going. As he passed by a cave, he saw something move. \"Who\\'s there?\" called the knight.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae303dcc-93a1-425d-a7ff-2f9ae08090f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" He walked into the cave and saw a giant dragon curled up and snoring. The knight was frightened, but he couldn't leave the dragon behind. So he decided to hide behind a tree and wait. Just then, the dragon woke up and started roaring.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "292366be-f5a4-4b17-ac57-4a2381c92e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The knight had never killed anyone before, but he had no choice but to kill the dragon. His sword struck the dragon's heart. The dragon screamed and fumbled about. His enormous body hit the roof of the cave and fell to the ground.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d0e4b-a6b1-4074-8d38-9cbe5a07a37e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohere_hackathon",
   "language": "python",
   "name": "cohere_hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
