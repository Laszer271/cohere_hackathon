{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f111a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import json\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from stability_sdk import client\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "    \n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from app.story_generator.segmentation import StoryDivider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17793be-d946-4e5a-851d-39201af6b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_story():\n",
    "    stories_path = os.path.join(os.path.abspath(''), os.pardir,\n",
    "                                \"data\", \"stories\", \"fairy_tales.json\")\n",
    "    with open(stories_path, \"rb\") as f:\n",
    "        stories = json.load(f)\n",
    "        example_story = random.choice(stories)\n",
    "    return example_story\n",
    "\n",
    "\n",
    "def get_segmented_story(n_pages=None, sentences_per_page=3):\n",
    "    story = get_random_story()\n",
    "    seg = StoryDivider(story[\"title\"], story[\"text\"])\n",
    "    segmented = seg.divide_story_into_segments(n_pages=n_pages, sentences_per_page=sentences_per_page)\n",
    "    # print(segmented)\n",
    "    return seg.story_id, segmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6ced5",
   "metadata": {},
   "source": [
    "# APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c32711-8021-43ae-acb1-a2332a69e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cohere_api_key.txt', 'r') as f:\n",
    "    cohere_api_key = f.read()\n",
    "co = cohere.Client(cohere_api_key)\n",
    "\n",
    "with open('../stability_api_key.txt', 'r') as f:\n",
    "    stability_api_key = f.read()\n",
    "stability_api = client.StabilityInference(\n",
    "    key=stability_api_key, \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "del cohere_api_key\n",
    "del stability_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75020b35",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60691af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/stories/fairy_tales.json', errors='ignore') as f:\n",
    "    data = json.load(f)\n",
    "    # text = data['text']\n",
    "    # print(type(text), len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = data[0]\n",
    "title = story['title']\n",
    "text = story['text']\n",
    "print(title)\n",
    "print()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39950a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story in data:\n",
    "    print(story['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275800b3-a518-4f64-97d5-1498be743209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# story_title_1, random_story_1 = get_segmented_story(sentences_per_page=5)\n",
    "# random_story_2 = random_story_1\n",
    "\n",
    "# while random_story_1[0] == random_story_2[0]:\n",
    "#     story_title_2, random_story_2 = get_segmented_story(sentences_per_page=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68574f",
   "metadata": {},
   "source": [
    "# Generating stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dab670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, model=\"xlarge\", \n",
    "             num_generations=5, temperature=0.7, \n",
    "             max_tokens=2000, stop_sequences=['<end>']):\n",
    "             \n",
    "  prediction = co.generate(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    return_likelihoods = 'GENERATION',\n",
    "    stop_sequences=stop_sequences,\n",
    "    max_tokens=max_tokens,\n",
    "    temperature=temperature,\n",
    "    num_generations=num_generations)\n",
    "  \n",
    "  # Get list of generations\n",
    "  gens = []\n",
    "  likelihoods = []\n",
    "  for gen in prediction.generations:\n",
    "      gens.append(gen.text)\n",
    "      \n",
    "      sum_likelihood = 0\n",
    "      for t in gen.token_likelihoods:\n",
    "          sum_likelihood += t.likelihood\n",
    "      # Get sum of likelihoods\n",
    "      likelihoods.append(sum_likelihood)\n",
    "\n",
    "  pd.options.display.max_colwidth = 200\n",
    "  # Create a dataframe for the generated sentences and their likelihood scores\n",
    "  df = pd.DataFrame({'generation': gens, 'likelihood': likelihoods})\n",
    "  # Drop duplicates\n",
    "  df = df.drop_duplicates(subset=['generation'])\n",
    "  # Sort by highest sum likelihood\n",
    "  df = df.sort_values('likelihood', ascending=False, ignore_index=True)\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2122d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUPDnAyKRbnK",
    "outputId": "adda1e5a-9650-498a-a24c-cd23ac4a9621"
   },
   "outputs": [],
   "source": [
    "def generate_image(image_prompt):\n",
    "  # the object returned is a python generator\n",
    "  answers = stability_api.generate(\n",
    "      prompt=image_prompt\n",
    "  )\n",
    "\n",
    "  # iterating over the generator produces the api response\n",
    "  for resp in answers:\n",
    "      for artifact in resp.artifacts:\n",
    "          if artifact.finish_reason == generation.FILTER:\n",
    "              warnings.warn(\n",
    "                  \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                  \"Please modify the prompt and try again.\")\n",
    "          if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "              img = Image.open(io.BytesIO(artifact.binary))\n",
    "              display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9c3ec-a644-4063-acfb-7b7e73927fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_newline_at_the_end(text):\n",
    "    if text[-1] != '\\n':\n",
    "        text += '\\n'\n",
    "    return text\n",
    "\n",
    "# def generate_prompt_for_story_start(header: str,  examples: list, titles: list = None, story_title: str = None,\n",
    "#                                     pre_example_string: str = 'Answer: ', stop_token: str ='<end>', max_tokens: int = 1000):\n",
    "#     prompt = add_newline_at_the_end(header)\n",
    "    \n",
    "#     for i, ex in enumerate(examples):\n",
    "#         if titles is not None:\n",
    "#             prompt += 'Title: ' + add_newline_at_the_end(titles[i])\n",
    "#         prompt += pre_example_string\n",
    "#         prompt += add_newline_at_the_end(ex)\n",
    "#         prompt += add_newline_at_the_end(stop_token)\n",
    "        \n",
    "#     if titles is not None:\n",
    "#         prompt += 'Title: '\n",
    "#         if story_title is not None:\n",
    "#             prompt += add_newline_at_the_end(story_title)\n",
    "#             prompt += pre_example_string\n",
    "#     else:\n",
    "#         prompt += pre_example_string\n",
    "    \n",
    "    \n",
    "#     estimated_tokens_number = len(prompt.split(' ')) + len(ex.split(' '))\n",
    "#     estimated_tokens_number *= 2 # let's assume word is on averate 2 tokens\n",
    "#     assert estimated_tokens_number < max_tokens, f'Estimated number of tokens was {estimated_tokens_number} which is more than specified max number of tokens ({max_tokens})' \n",
    "    \n",
    "#     return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282b41f-8f11-4af8-ba93-52caa64b6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_stories(n=3):\n",
    "    stories_path = os.path.join(os.path.abspath(''), os.pardir,\n",
    "                                \"data\", \"stories\", \"fairy_tales.json\")\n",
    "    with open(stories_path, \"rb\") as f:\n",
    "        stories = json.load(f)\n",
    "        assert n <= len(stories), f'Tried to get {n} stories while is only {len(stories)} stories in the database'\n",
    "        example_stories = list(np.random.choice(stories, size=n, replace=False))\n",
    "        \n",
    "    return example_stories\n",
    "\n",
    "def get_segment_of_stories(stories: list, segment_idx: int, handle_too_big_index=True,\n",
    "                           n_pages=None, sentences_per_page=3):\n",
    "    segmented_stories = []\n",
    "    for s in stories:\n",
    "        seg = StoryDivider(s[\"title\"], s[\"text\"])\n",
    "        segmented = seg.divide_story_into_segments(n_pages=n_pages, sentences_per_page=sentences_per_page)\n",
    "        if handle_too_big_index and segment_idx >= len(segmented):\n",
    "            index = len(segmented) - 2\n",
    "            \n",
    "        segmented_stories.append({'title': seg.story_id, 'text': segmented[segment_idx]})\n",
    "        \n",
    "    return segmented_stories\n",
    "\n",
    "def generate_prompt_for_story_start(stories: list, keys_to_use: list, header: str, parameters: list = None,  \n",
    "                                    stop_token: str ='<end>', max_tokens: int = 1000):\n",
    "    assert parameters is None or len(parameters) == len(keys_to_use) - 1\n",
    "    # assert keys_to_use[-1] == 'text'    \n",
    "    \n",
    "    prompt = add_newline_at_the_end(header) + '\\n'\n",
    "    \n",
    "    avg_story_length = 0\n",
    "    for i, story in enumerate(stories):\n",
    "        avg_story_length += len(story[keys_to_use[-1]])\n",
    "        for key in keys_to_use:\n",
    "            prompt += f'{key.capitalize()}: {story[key]}'\n",
    "            prompt = add_newline_at_the_end(prompt)\n",
    "        prompt += add_newline_at_the_end(stop_token)\n",
    "    avg_story_length = avg_story_length // len(stories)\n",
    "        \n",
    "    for key, param in zip(keys_to_use[:-1], parameters):\n",
    "        prompt += f'{key.capitalize()}: '\n",
    "        if not param:\n",
    "            break\n",
    "        else:\n",
    "            prompt += add_newline_at_the_end(param)\n",
    "    \n",
    "    if param:\n",
    "        prompt += f'{keys_to_use[-1].capitalize()}: '\n",
    "            \n",
    "    estimated_tokens_number = len(prompt.split(' ')) + avg_story_length\n",
    "    estimated_tokens_number *= 2 # let's assume word is on averate 2 tokens\n",
    "    assert estimated_tokens_number < max_tokens, f'Estimated number of tokens was {estimated_tokens_number} which is more than specified max number of tokens ({max_tokens})' \n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def print_result(result, parameters, keys_used):\n",
    "    starting_string = ''\n",
    "    break_used = False\n",
    "    for param, key in zip(parameters, keys_used[:-1]):\n",
    "        starting_string += f'{key.capitalize()}: '\n",
    "        if param:\n",
    "            starting_string += param\n",
    "        else: \n",
    "            break_used = True\n",
    "            break\n",
    "\n",
    "        starting_string = add_newline_at_the_end(starting_string)\n",
    "\n",
    "    if not break_used:\n",
    "        starting_string += f'{keys_used[-1].capitalize()}:'\n",
    "\n",
    "    for i, row in result.iterrows():\n",
    "        print('-'*50)\n",
    "        print('likelihood:', row['likelihood'])\n",
    "\n",
    "        print(starting_string + row[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010eaffb-f4fd-4132-88f9-da64c08f7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 1000\n",
    "STOP_SEQUENCES = ['<end>']\n",
    "TEMPERATURE = 0.7\n",
    "MODEL = 'xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c273d7b-66cf-457b-9d68-2b672aec73c4",
   "metadata": {},
   "source": [
    "<h2>Generating beginning of the story</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a2823-cc73-48fd-ba9e-da7b64bc9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_stories = get_n_stories(3)\n",
    "example_beginnings = get_segment_of_stories(example_stories, 0)\n",
    "\n",
    "keys_to_use = ['title', 'text']\n",
    "header = 'Exercise: Generate the beginning of the story for children based on a information given.'\n",
    "parameters = ['Two Little Pigs That Tried To Learn Programming']\n",
    "\n",
    "prompt = generate_prompt_for_story_start(example_beginnings, keys_to_use, header, parameters, stop_token=STOP_SEQUENCES[0])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbcd811-1743-46bc-98e4-2c2262e993bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7affb95-588a-4b1c-a5af-e8e0eaaf61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = [random_story_1[0], random_story_2[0]]\n",
    "# titles = [story_title_1, story_title_2]\n",
    "# story_title = 'The Dragon and prince penguin' # should be None if there is \n",
    "# MAX_TOKENS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c48f7-5f5d-425c-91bd-26fdb2b8dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = generate_prompt_for_story_start(header, examples, titles=titles, story_title=story_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98823dd3-aa37-46bd-a28b-cffa3e122424",
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_result = generate(\n",
    "    prompt,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    stop_sequences=STOP_SEQUENCES,\n",
    "    temperature=TEMPERATURE,\n",
    "    model=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f22e4e-a7df-46c4-9345-80a18f8d3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result(beg_result, parameters, keys_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f55ecc-79eb-4045-b7c4-2fc14e337030",
   "metadata": {},
   "source": [
    "<h2>Generating continuation - strategy 1: Structured prompt</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3064e-0d81-424e-8989-c2422406494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_continuations = get_segment_of_stories(example_stories, 1)\n",
    "example_continuations = example_continuations[:1]\n",
    "for i, cont in enumerate(example_continuations):\n",
    "        cont['Previous Part'] = example_beginnings[i]['text']\n",
    "        cont['Continuation'] = cont['text']\n",
    "        del cont['text']\n",
    "\n",
    "keys_to_use = ['title', 'Previous Part', 'Continuation']\n",
    "header = 'Exercise: Generate the continuation of the story for children based on the title and previous part given.'\n",
    "parameters = ['Two Little Pigs That Tried To Learn Programming', beg_result.iloc[0]['generation'].replace(STOP_SEQUENCES[0], '')]\n",
    "\n",
    "\n",
    "prompt = generate_prompt_for_story_start(example_continuations, keys_to_use, header, parameters)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570d54c-94a1-4d40-89cf-7a9ec7045b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_result = generate(\n",
    "    prompt,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    stop_sequences=STOP_SEQUENCES,\n",
    "    temperature=TEMPERATURE,\n",
    "    model=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3aa83-df23-4de3-ab79-c347b76f88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result(cont_result, parameters, keys_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27152642-19bf-4d5c-becc-26be8aded6a3",
   "metadata": {},
   "source": [
    "<h2>Generating continuation - strategy 2: No examples</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53da147-4065-4f56-a3b2-78e638daeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "prompt = f'Story title: {parameters[0]}\\n'\n",
    "prompt += beg_result.iloc[0]['generation'].replace(STOP_SEQUENCES[0], '')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5839c-8bd8-40f3-b35e-0e70184eeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cont_result_2 = generate(\n",
    "    prompt,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    stop_sequences=STOP_SEQUENCES,\n",
    "    temperature=TEMPERATURE,\n",
    "    model=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b2679-d17c-4a35-a100-af4c7adc6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in cont_result_2.iterrows():\n",
    "    print('-'*50)\n",
    "    print(prompt + row['generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc0190-a14e-4829-8561-ef39f8187348",
   "metadata": {},
   "source": [
    "<strong>Seems like the first approach is better so let's go with that</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979e0ad-677b-4988-bbf8-f0e6cb831067",
   "metadata": {},
   "source": [
    "<h2>Generating ending</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cebd607-48a9-4dea-bb51-30af6943d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE: here we use 2 first fragment of each story and the last fragment.\n",
    "# It probably would be better to use 3 last fragments or summarization of the story so far and a last fragment\n",
    "example_endings = get_segment_of_stories(example_stories, -1)\n",
    "example_endings = example_endings[:1]\n",
    "for i, ending in enumerate(example_endings):\n",
    "    ending['Previous Part'] = example_continuations[0]['Previous Part'] + example_continuations[0]['Continuation']\n",
    "    ending['Story Ending'] = ending['text']\n",
    "    \n",
    "    del ending['text']\n",
    "    print(ending)\n",
    "\n",
    "keys_to_use = ['title', 'Previous Part', 'Story Ending']\n",
    "header = 'Exercise: Finish the story for children based on the title and previous part given.'\n",
    "\n",
    "# NOTE: here we use the whole stories generated so far. It may be impossible to do so in the application as \n",
    "generated_so_far = beg_result.iloc[0]['generation'].replace(STOP_SEQUENCES[0], '') + cont_result.iloc[0]['generation'].replace(STOP_SEQUENCES[0], '')\n",
    "parameters = ['Two Little Pigs That Tried To Learn Programming', generated_so_far]\n",
    "\n",
    "\n",
    "prompt = generate_prompt_for_story_start(example_endings, keys_to_use, header, parameters)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3b213-5a68-40bc-8279-fb30e2d321e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_result = generate(\n",
    "    prompt,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    stop_sequences=STOP_SEQUENCES,\n",
    "    temperature=TEMPERATURE,\n",
    "    model=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a81726-c280-4e42-a2c7-dcaa7adfe63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result(end_result, parameters, keys_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f49346-ac38-4195-abe5-76c9f3780cdb",
   "metadata": {},
   "source": [
    "<h1>Old</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ca88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14efc750-472b-40da-a911-9bea0fe809a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.iloc[0]['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469519fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result['generation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_string = \"\"\"\n",
    "# Once upon a time, there was a farmer with three little pigs. He did not have enough food to take care of his pigs so he sent them away to take care of themselves. The first little pig was walking on the road. Suddenly he saw a man with some straws. He could  build a house with the straws, he said to himself and asked the man to give him his straws. The man was kind so he gave the first little pig his straws. The pig used the straws to build a straw house and danced around. Suddenly, a big bad wo\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51633c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a360b78c71b5f49ff292419317a20d8854e0163ad331d295b8b4eaeec07fff6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
