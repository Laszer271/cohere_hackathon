{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f111a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import json\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from stability_sdk import client\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6ced5",
   "metadata": {},
   "source": [
    "# APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c32711-8021-43ae-acb1-a2332a69e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cohere_api_key.txt', 'r') as f:\n",
    "    cohere_api_key = f.read()\n",
    "co = cohere.Client(cohere_api_key)\n",
    "\n",
    "with open('../stability_api_key.txt', 'r') as f:\n",
    "    stability_api_key = f.read()\n",
    "stability_api = client.StabilityInference(\n",
    "    key=stability_api_key, \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "del cohere_api_key\n",
    "del stability_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75020b35",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60691af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 3286\n"
     ]
    }
   ],
   "source": [
    "with open('../stories/hansel_and_gretel.json') as f:\n",
    "    data = json.load(f)\n",
    "    text = data['text']\n",
    "    print(type(text), len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df014c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 3645\n"
     ]
    }
   ],
   "source": [
    "with open('../stories/red_riding_hood.json') as f:\n",
    "    data = json.load(f)\n",
    "    text = data['text']\n",
    "    print(type(text), len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9e9f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 3403\n"
     ]
    }
   ],
   "source": [
    "with open('../stories/three_little_pigs.json', errors='ignore') as f:\n",
    "    data = json.load(f)\n",
    "    text = data['text']\n",
    "    print(type(text), len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68574f",
   "metadata": {},
   "source": [
    "# Generating stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71dab670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, model=\"xlarge\", \n",
    "             num_generations=5, temperature=0.7, \n",
    "             max_tokens=2000, stop_sequences=['<end>']):\n",
    "             \n",
    "  prediction = co.generate(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    return_likelihoods = 'GENERATION',\n",
    "    stop_sequences=stop_sequences,\n",
    "    max_tokens=max_tokens,\n",
    "    temperature=temperature,\n",
    "    num_generations=num_generations)\n",
    "  \n",
    "  # Get list of generations\n",
    "  gens = []\n",
    "  likelihoods = []\n",
    "  for gen in prediction.generations:\n",
    "      gens.append(gen.text)\n",
    "      \n",
    "      sum_likelihood = 0\n",
    "      for t in gen.token_likelihoods:\n",
    "          sum_likelihood += t.likelihood\n",
    "      # Get sum of likelihoods\n",
    "      likelihoods.append(sum_likelihood)\n",
    "\n",
    "  pd.options.display.max_colwidth = 200\n",
    "  # Create a dataframe for the generated sentences and their likelihood scores\n",
    "  df = pd.DataFrame({'generation':gens, 'likelihood': likelihoods})\n",
    "  # Drop duplicates\n",
    "  df = df.drop_duplicates(subset=['generation'])\n",
    "  # Sort by highest sum likelihood\n",
    "  df = df.sort_values('likelihood', ascending=False, ignore_index=True)\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c2122d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUPDnAyKRbnK",
    "outputId": "adda1e5a-9650-498a-a24c-cd23ac4a9621"
   },
   "outputs": [],
   "source": [
    "def generate_image(image_prompt):\n",
    "  # the object returned is a python generator\n",
    "  answers = stability_api.generate(\n",
    "      prompt=image_prompt\n",
    "  )\n",
    "\n",
    "  # iterating over the generator produces the api response\n",
    "  for resp in answers:\n",
    "      for artifact in resp.artifacts:\n",
    "          if artifact.finish_reason == generation.FILTER:\n",
    "              warnings.warn(\n",
    "                  \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                  \"Please modify the prompt and try again.\")\n",
    "          if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "              img = Image.open(io.BytesIO(artifact.binary))\n",
    "              display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98823dd3-aa37-46bd-a28b-cffa3e122424",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate(\n",
    "    \"write a fairy tale\",\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a42ca88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   generation  5 non-null      object \n",
      " 1   likelihood  5 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 208.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(result.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "469519fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for adults (well, sort of).\n",
      "I was intrigued.\n",
      "\n",
      "It was only the first paragraph, but I was hooked.\n",
      "Then I was laughing.\n",
      "Then I was thinking, \"Where is this story going?\"\n",
      "\n",
      "I am happy to report that I loved the entire book.\n",
      "It was such a fun, interesting read.\n",
      "I read the entire thing in one night.\n",
      "I didn't want to stop.\n",
      "I was just too curious to see how the story would end.\n",
      "\n",
      "The author had a very unique writing style.\n",
      "I really liked it.\n",
      "It was simple, yet complex.\n",
      "It made me want to keep reading.\n",
      "It made me want to keep turning the pages.\n",
      "\n",
      "It's not often that I read a book and like the main character so much.\n",
      "There are just so many good things to say about her.\n",
      "She is smart, determined, funny, and brave.\n",
      "I loved the way she saw the world.\n",
      "\n",
      "I really enjoyed the story.\n",
      "I am happy to report that it did not end the way I expected.\n",
      "It had a lot of twists and turns.\n",
      "\n",
      "There were many funny lines in the book.\n",
      "The one that made me laugh the most was the following:\n",
      "\"People say love conquers all. But that's not true. Love doesn't conquer all. It just makes you more vulnerable.\"\n",
      "\n",
      "I have not read anything else by this author.\n",
      "I was surprised to see that this is the author's debut novel.\n",
      "I really enjoyed her writing style.\n",
      "I will be reading more of her books in the future.\n",
      "\n",
      "This book was not at all what I expected.\n",
      "It was better than I expected.\n",
      "It was a fun, entertaining, interesting, and fast-paced read.\n",
      "\n",
      "The book started out as a light-hearted story.\n",
      "It started out as a funny, light-hearted, and enjoyable story.\n",
      "Then the story became darker and more serious.\n",
      "I loved the way the story changed.\n",
      "It was very interesting to read.\n",
      "\n",
      "I have read several books by this author.\n",
      "I always enjoy her books.\n",
      "They are always well-written and fun to read.\n",
      "\n",
      "I have been reading a lot of books lately.\n",
      "I have been reading books that are part of a series.\n",
      "I am happy to report that this book was not part of a series.\n",
      "I was happy about that.\n",
      "I do not want to have to wait to read the next book in the series.\n",
      "\n",
      "I have not read anything else by this author.\n",
      "I have not read anything else by this author.\n",
      "I have not read anything else by this author.\n",
      "\n",
      "This book was an easy, fast-paced read.\n",
      "I really enjoyed it.\n",
      "It was a fun, entertaining, and interesting read.\n",
      "I would recommend it to anyone.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my own.\n",
      "I was not paid to write this review.\n",
      "\n",
      "I received a free copy of this book from the author.\n",
      "All opinions expressed are my\n"
     ]
    }
   ],
   "source": [
    "print(result['generation'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b00c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a360b78c71b5f49ff292419317a20d8854e0163ad331d295b8b4eaeec07fff6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
