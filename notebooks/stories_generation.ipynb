{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f111a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import json\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from stability_sdk import client\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6ced5",
   "metadata": {},
   "source": [
    "# APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c32711-8021-43ae-acb1-a2332a69e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cohere_api_key.txt', 'r') as f:\n",
    "    cohere_api_key = f.read()\n",
    "co = cohere.Client(cohere_api_key)\n",
    "\n",
    "with open('../stability_api_key.txt', 'r') as f:\n",
    "    stability_api_key = f.read()\n",
    "stability_api = client.StabilityInference(\n",
    "    key=stability_api_key, \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "del cohere_api_key\n",
    "del stability_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75020b35",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60691af1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../stories/hansel_and_gretel.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m../stories/hansel_and_gretel.json\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      3\u001b[0m     text \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\__repos\\cohere_hackathon\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../stories/hansel_and_gretel.json'"
     ]
    }
   ],
   "source": [
    "with open('../stories/hansel_and_gretel.json') as f:\n",
    "    data = json.load(f)\n",
    "    text = data['text']\n",
    "    print(type(text), len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df014c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 3645\n"
     ]
    }
   ],
   "source": [
    "with open('../stories/red_riding_hood.json') as f:\n",
    "    data = json.load(f)\n",
    "    text = data['text']\n",
    "    print(type(text), len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e9f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 3403\n"
     ]
    }
   ],
   "source": [
    "with open('../stories/three_little_pigs.json', errors='ignore') as f:\n",
    "    data = json.load(f)\n",
    "    text = data['text']\n",
    "    print(type(text), len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68574f",
   "metadata": {},
   "source": [
    "# Generating stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71dab670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, model=\"xlarge\", \n",
    "             num_generations=5, temperature=0.7, \n",
    "             max_tokens=2000, stop_sequences=['<end>']):\n",
    "             \n",
    "  prediction = co.generate(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    return_likelihoods = 'GENERATION',\n",
    "    stop_sequences=stop_sequences,\n",
    "    max_tokens=max_tokens,\n",
    "    temperature=temperature,\n",
    "    num_generations=num_generations)\n",
    "  \n",
    "  # Get list of generations\n",
    "  gens = []\n",
    "  likelihoods = []\n",
    "  for gen in prediction.generations:\n",
    "      gens.append(gen.text)\n",
    "      \n",
    "      sum_likelihood = 0\n",
    "      for t in gen.token_likelihoods:\n",
    "          sum_likelihood += t.likelihood\n",
    "      # Get sum of likelihoods\n",
    "      likelihoods.append(sum_likelihood)\n",
    "\n",
    "  pd.options.display.max_colwidth = 200\n",
    "  # Create a dataframe for the generated sentences and their likelihood scores\n",
    "  df = pd.DataFrame({'generation':gens, 'likelihood': likelihoods})\n",
    "  # Drop duplicates\n",
    "  df = df.drop_duplicates(subset=['generation'])\n",
    "  # Sort by highest sum likelihood\n",
    "  df = df.sort_values('likelihood', ascending=False, ignore_index=True)\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c2122d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUPDnAyKRbnK",
    "outputId": "adda1e5a-9650-498a-a24c-cd23ac4a9621"
   },
   "outputs": [],
   "source": [
    "def generate_image(image_prompt):\n",
    "  # the object returned is a python generator\n",
    "  answers = stability_api.generate(\n",
    "      prompt=image_prompt\n",
    "  )\n",
    "\n",
    "  # iterating over the generator produces the api response\n",
    "  for resp in answers:\n",
    "      for artifact in resp.artifacts:\n",
    "          if artifact.finish_reason == generation.FILTER:\n",
    "              warnings.warn(\n",
    "                  \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                  \"Please modify the prompt and try again.\")\n",
    "          if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "              img = Image.open(io.BytesIO(artifact.binary))\n",
    "              display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98823dd3-aa37-46bd-a28b-cffa3e122424",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate(\n",
    "    \"short fairy tale about a girl\",\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a42ca88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   generation  5 non-null      object \n",
      " 1   likelihood  5 non-null      float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 208.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(result.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469519fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " who's trying to put on a dress. But\n",
      "as the story progresses, it's revealed that she's putting on a\n",
      "dress of flowers, and that she's a princess who is going to marry a\n",
      "frog.\n",
      "\n",
      "The story has a pretty simple\n",
      "plot, but it's also a pretty good one. It's one of those stories that\n",
      "I've read over and over again, and it never gets old. I also like the\n",
      "story because it's very funny. I can't help but laugh when the\n",
      "princess gets stuck in her dress.\n",
      "\n",
      "This story is very similar to\n",
      "the original, but it's also a bit different. In this story, the girl\n",
      "is not a princess, but she is a fairy. She is trying to put on a\n",
      "dress, but she is wearing a dress of flowers. She is also not a\n",
      "princess, but she is a princess.\n",
      "\n",
      "This is a story that is very similar to the original, but it is a bit different. In this story, the girl is not a princess, but she is a fairy. She is trying to put on a dress, but she is wearing a dress of flowers. She is also not a princess, but she is a princess.\n",
      "\n",
      "I like this story because it is very funny. It is funny because it is a story about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "I think this story is very funny because it is about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "I think this story is very funny because it is about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "I love that she is not a princess. I think it's great that she is not a princess because it's not like she's a princess who is a princess. It's a story about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It's also funny because it's a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "I love this story because it is about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "I think it's a good story because it's about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "I love that she is not a princess because it is a story about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "It is also funny because it is a story about a girl who is not a princess, but she is a princess. I love that she is not a princess because it is a story about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "I love that she is not a princess because it is a story about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "I think that the princess thing is a great story. I think it's a great story because it is a story about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "This is a very good story because it is a story about a girl who is trying to put on a dress, but she is wearing a dress of flowers. It is also funny because it is a story about a girl who is not a princess, but she is a princess.\n",
      "\n",
      "I think this story is very good because it is a story about a girl who is trying to put on a dress, but she is wearing a dress of\n"
     ]
    }
   ],
   "source": [
    "print(result['generation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b00c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a360b78c71b5f49ff292419317a20d8854e0163ad331d295b8b4eaeec07fff6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
